# Dockerized vLLM for Serving Custom LLM Models via OpenAI API
An example of how to create a Docker image that initializes vllm and serves a custom large language model (LLM) through an OpenAI-compatible API interface. 
